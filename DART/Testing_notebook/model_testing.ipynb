{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from datetime import date, timedelta\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import requests\n",
    "from math import sqrt\n",
    "import math\n",
    "import yaml\n",
    "import traceback\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBase:\n",
    "    def __init__(self,\n",
    "                start_train_date: str,\n",
    "                end_train_date: str,\n",
    "                start_test_date: str,\n",
    "                end_test_date: str,\n",
    "                data_dir: str,\n",
    "                hour_forecast = 3,\n",
    "                lookback_days = 7,\n",
    "                batch_size = 32,\n",
    "                train_shuffle = True,\n",
    "                val_shuffle = False,\n",
    "                cv = True,\n",
    "                k = 5,\n",
    "                trading_hub = 'Houston',\n",
    "                train_split = 0.7,\n",
    "                predict_variable = 'ACTUAL_ERC_HLoad_excessive'\n",
    "                ):\n",
    "        \n",
    "\n",
    "        self.start_train_date = start_train_date\n",
    "        self.end_train_date = end_train_date\n",
    "        self.start_test_date = start_test_date\n",
    "        self.end_test_date = end_test_date\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.train_shuffle = train_shuffle\n",
    "        self.val_shuffle = val_shuffle\n",
    "        self.cv = cv\n",
    "        self.k = k\n",
    "        self.trading_hub = trading_hub\n",
    "        self.train_split = train_split\n",
    "        self.predict_variable = predict_variable\n",
    "\n",
    "\n",
    "        self.price_data_path = f'{data_dir}/2023_24_ERCOT_forecast_actual_data_v3.csv'\n",
    "\n",
    "        self.hour_forecast = hour_forecast\n",
    "        self.lookback_days = lookback_days\n",
    "\n",
    "        self.variable_selected = ['ACTUAL_ERC_Load', 'ACTUAL_ERC_HLoad', 'ACTUAL_ERC_NLoad',\n",
    "                                    'ACTUAL_ERC_SLoad', 'ACTUAL_ERC_WLoad', 'ACTUAL_ERC_CWind',\n",
    "                                    'ACTUAL_ERC_NWind', 'ACTUAL_ERC_PWind', 'ACTUAL_ERC_SWind',\n",
    "                                    'ACTUAL_ERC_Wind', 'ACTUAL_ERC_WWind', 'ACTUAL_ERC_Solar',\n",
    "                                    f'SP_Price_{trading_hub}',f'DA_Price_{trading_hub}']\n",
    "\n",
    "\n",
    "    def _get_date_list(self, start_date, end_date):\n",
    "        '''\n",
    "        Get date list between start_date and end_date in forat \"yyyymmdd\"\n",
    "        '''\n",
    "        start_date = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "        end_date = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "        date_list = []\n",
    "        \n",
    "        while start_date <= end_date:\n",
    "            date_list.append(start_date.strftime(\"%Y%m%d\"))\n",
    "            start_date += timedelta(days=1)\n",
    "\n",
    "        return date_list\n",
    "    \n",
    "    def _get_price_data(self):\n",
    "        self.price_data_df = pd.read_csv(self.price_data_path)\n",
    "\n",
    "        \n",
    "\n",
    "        self.hub = self.price_data_df.loc[:,['marketday', 'hourending'] + self.variable_selected].copy()\n",
    "\n",
    "        self.hub.loc[:,f'{self.trading_hub}_DART'] = self.hub.loc[:,f'SP_Price_{self.trading_hub}'] - self.hub.loc[:,f'DA_Price_{self.trading_hub}']\n",
    "        self.hub['date_int'] = pd.to_datetime(self.hub['marketday'], format='%m/%d/%Y').dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "        self.hub.index = self.hub['date_int'] * 100 + self.hub['hourending'].astype(int)\n",
    "        #calculate the excessive value\n",
    "        for value in self.variable_selected + [f'{self.trading_hub}_DART']:\n",
    "            hour_group_mean = self.hub.groupby('hourending')[value].rolling(self.lookback_days).mean().reset_index().rename(columns={value:f'{value}_mean',\n",
    "                                                                                                                                                  'level_1':'timestamp'})\n",
    "            # print(hour_group_mean[hour_group_mean['hourending'] == 2].iloc[:10,:])\n",
    "            hour_group_mean.index = hour_group_mean.timestamp\n",
    "            hour_group_std = self.hub.groupby('hourending')[value].rolling(self.lookback_days).std().reset_index().rename(columns={value:f'{value}_std',\n",
    "                                                                                                                                                  'level_1':'timestamp'})\n",
    "            hour_group_std.index = hour_group_std.timestamp\n",
    "            # self.houston = self.houston.merge(hour_group_mean.loc[:,[f'{value}_mean','timestamp']], on=['timestamp'], how='left')\n",
    "            self.hub  = pd.concat([self.hub, hour_group_mean.loc[:,[f'{value}_mean']],hour_group_std.loc[:,[f'{value}_std']]], axis=1)\n",
    "            \n",
    "            self.hub[f'{value}_excessive'] = (self.hub[value] - self.hub[f'{value}_mean']) / self.hub[f'{value}_std']\n",
    "            \n",
    "            # print(self.houston[self.houston['date_int'] == 20230201])\n",
    "            \n",
    "            # raise Exception('stop')\n",
    "        self.hub.loc[:,'datetime'] = self.hub.index\n",
    "        self.hub = self.hub.dropna()\n",
    "\n",
    "        #get all the unique dates\n",
    "        all_dates = self.hub['date_int'].unique()\n",
    "\n",
    "        #create a dataframe with date_int and hour_ending 1-24\n",
    "        all_hours = range(1, 25)  # Hours 1-24\n",
    "        multi_index = pd.MultiIndex.from_product(\n",
    "                                                    [all_dates, all_hours],\n",
    "                                                    names=['date_int', 'hourending']\n",
    "                                                )\n",
    "        \n",
    "        self.hub = (\n",
    "                        self.hub.set_index(['date_int', 'hourending'])\n",
    "                        .reindex(multi_index)\n",
    "                        .reset_index()\n",
    "                    )\n",
    "\n",
    "        # Sort by date and hourending (optional)\n",
    "        self.hub.sort_values(['date_int', 'hourending'], inplace=True)\n",
    "\n",
    "        self.hub = self.hub.ffill()\n",
    "        # print(self.hub[self.hub['marketday'] == '2/15/2023'])\n",
    "\n",
    "    def _get_date_one_days_later(self,date_str):\n",
    "        # Convert string to datetime object\n",
    "        date_obj = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "        \n",
    "        # Add two days\n",
    "        future_date_obj = date_obj + timedelta(days=1)\n",
    "        \n",
    "        # Convert back to string in YYYYMMDD format\n",
    "        future_date_str = future_date_obj.strftime(\"%Y%m%d\")\n",
    "    \n",
    "        return future_date_str\n",
    "    \n",
    "    def _get_date_x_days_before(self,date_str,x=1):\n",
    "        # Convert string to datetime object\n",
    "        date_obj = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "        past_date_obj = date_obj - timedelta(days=x)\n",
    "        \n",
    "        # Convert back to string in YYYYMMDD format\n",
    "        past_date_str = past_date_obj.strftime(\"%Y%m%d\")\n",
    "    \n",
    "        return past_date_str\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_data_list(self,modes):\n",
    "        weather_data_list = []\n",
    "        time_series_lookback_list = []\n",
    "        time_series_forecast_list = []\n",
    "\n",
    "        if modes == 'train':\n",
    "            self.date_list = self._get_date_list(self.start_train_date, self.end_train_date)\n",
    "        elif modes == 'test':\n",
    "            self.date_list = self._get_date_list(self.start_test_date, self.end_test_date)\n",
    "        else:\n",
    "            raise ValueError('modes should be either train or test')\n",
    "\n",
    "        for date_str in self.date_list:\n",
    "            date = int(date_str)\n",
    "\n",
    "            yesterday = self._get_date_x_days_before(date_str,x=1)\n",
    "\n",
    "            start_lookback_date = self._get_date_x_days_before(date_str,x=self.lookback_days+1)\n",
    "            \n",
    "            #get the time series data\n",
    "            time_series_lookback = self.hub.loc[(self.hub['date_int'] < int(yesterday))].copy()\n",
    "            date_unique = time_series_lookback['date_int'].unique()\n",
    "\n",
    "            if len(date_unique) < self.lookback_days:\n",
    "                continue\n",
    "\n",
    "            time_series_lookback = time_series_lookback[time_series_lookback['date_int'].isin(date_unique[-self.lookback_days:])]\n",
    "            \n",
    "\n",
    "            time_series_forecast = self.hub.loc[self.hub['date_int'] == date].copy()\n",
    "\n",
    "            if len(time_series_forecast) == 0:\n",
    "                continue\n",
    "\n",
    "            # print(self.hub[self.hub['marketday'] == '2/15/2023'])\n",
    "            # print(date_str)\n",
    "            # print(time_series_lookback.date_int.unique())\n",
    "            # print(time_series_lookback)\n",
    "            # print(time_series_forecast)\n",
    "            # raise ValueError\n",
    "\n",
    "            forecast_date = self._get_date_one_days_later(date_str)\n",
    "            weather_data_path = f'{self.data_dir}/GFS_forecast/forecast_{date}_on_{yesterday}.pkl'\n",
    "            # print(weather_data_path)\n",
    "            with open(weather_data_path, 'rb') as file:\n",
    "                daily_weather_data = pickle.load(file)\n",
    "\n",
    "            # print(daily_weather_data.keys())\n",
    "            #print(daily_weather_data['data'].shape)\n",
    "\n",
    "\n",
    "            prediction_frequency = len(daily_weather_data['hour_forecast']) \n",
    "            if prediction_frequency * self.hour_forecast != 24:\n",
    "                raise ValueError(f'hour_forecast len {prediction_frequency} or {self.hour_forecast} not correct')\n",
    "\n",
    "            for i in range(prediction_frequency):\n",
    "                #print(len(time_series_lookback))\n",
    "                # if '3/12/2023' in time_series_lookback.marketday.values:\n",
    "                #     print(len(time_series_lookback))\n",
    "                #     print(time_series_lookback[time_series_lookback.marketday == '3/12/2023'])\n",
    "                #     print(time_series_lookback.groupby('marketday').count())\n",
    "                #     raise Exception('stop')\n",
    "                time_series_lookback_list.append(time_series_lookback)\n",
    "                time_series_forecast_list.append(time_series_forecast.iloc[i*self.hour_forecast:(i+1)*self.hour_forecast])\n",
    "                # print(len(time_series_forecast.iloc[i*self.hour_forecast:(i+1)*self.hour_forecast]))\n",
    "                weather_data_list.append(daily_weather_data['data'][i,:,:,:])\n",
    "\n",
    "                # print(self.time_series_forecast_list[0].datetime)\n",
    "                # print(self.time_series_lookback_list[0])                \n",
    "\n",
    "                # raise Exception('stop')\n",
    "            # print(len(self.weather_data_list))\n",
    "            # print(len(self.time_series_lookback_list))\n",
    "            # print(len(self.time_series_forecast_list))\n",
    "        return weather_data_list, time_series_lookback_list, time_series_forecast_list  \n",
    "\n",
    "    def create_dataloader(self):\n",
    "\n",
    "        self._get_price_data()\n",
    "\n",
    "        weather_data_list_train, time_series_lookback_list_train, time_series_forecast_list_train  = self._get_data_list(modes='train')\n",
    "        filtered_index = list(range(len(weather_data_list_train)))\n",
    "\n",
    "        if self.cv:\n",
    "            samples_in_fold = len(filtered_index)// self.k\n",
    "            split = int(samples_in_fold*self.train_split)\n",
    "\n",
    "            trainning_index_all = []\n",
    "            validation_index_all = []\n",
    "\n",
    "            for i in range(self.k):\n",
    "                trainning_index = filtered_index[i*samples_in_fold:i*samples_in_fold+split]\n",
    "                validation_index = filtered_index[i*samples_in_fold+split:(i+1)*samples_in_fold]\n",
    "\n",
    "                trainning_index_all = trainning_index_all + list(trainning_index)\n",
    "                validation_index_all = validation_index_all + list(validation_index)\n",
    "        else:\n",
    "            split = int(len(filtered_index)*self.train_split)\n",
    "\n",
    "            trainning_index_all = list(filtered_index[:split])\n",
    "            validation_index_all = list(filtered_index[split:])\n",
    "\n",
    "        excess_variables = [f'{v}_excessive' for v in self.variable_selected + [f'{self.trading_hub}_DART']]\n",
    "\n",
    "        all_variables = self.variable_selected + excess_variables + [f'{self.trading_hub}_DART']\n",
    "\n",
    "        trainning_dataset = BTDataset(weather_data_list_train, time_series_lookback_list_train, time_series_forecast_list_train, trainning_index_all, all_variables, self.predict_variable)\n",
    "        trainning_dataloader = DataLoader(trainning_dataset, batch_size=self.batch_size, shuffle=self.train_shuffle)\n",
    "\n",
    "        validation_dataset = BTDataset(weather_data_list_train, time_series_lookback_list_train, time_series_forecast_list_train, validation_index_all, all_variables, self.predict_variable)\n",
    "        validation_dataloader = DataLoader(validation_dataset, batch_size=self.batch_size, shuffle=self.val_shuffle)\n",
    "        \n",
    "        return trainning_dataloader, validation_dataloader\n",
    "        \n",
    "        \n",
    "\n",
    "class BTDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 weather_data_list,\n",
    "                 time_series_lookback_list,\n",
    "                 time_series_forecast_list,\n",
    "                 filtered_index,\n",
    "                 feature_required,\n",
    "                 predict_value,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.weather_data_list = weather_data_list\n",
    "        self.time_series_lookback_list = time_series_lookback_list\n",
    "        self.time_series_forecast_list = time_series_forecast_list\n",
    "        self.index_list = filtered_index\n",
    "        self.feature_required = feature_required\n",
    "        self.predict_value = predict_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        sample_index = self.index_list[index]\n",
    "        time_series_lookback_df = self.time_series_lookback_list[sample_index]\n",
    "        time_series_forecast_df = self.time_series_forecast_list[sample_index]\n",
    "        weather_data = self.weather_data_list[sample_index]\n",
    "\n",
    "        raw_data_ts = time_series_lookback_df.loc[:,self.feature_required].copy().values\n",
    "        raw_data_weather = weather_data.copy()\n",
    "        label = time_series_forecast_df.loc[:,self.predict_value].values\n",
    "\n",
    "        train_month = time_series_lookback_df['date_int'].values // 100 %100\n",
    "        train_day = time_series_lookback_df['date_int'].values % 100 \n",
    "        train_hour = time_series_lookback_df['hourending'].values\n",
    "\n",
    "        label_month = time_series_forecast_df['date_int'].values // 100 %100\n",
    "        label_day = time_series_forecast_df['date_int'].values % 100 \n",
    "        label_hour = time_series_forecast_df['hourending'].values\n",
    "        \n",
    "        # print(time_series_lookback_df['date_int'].values)\n",
    "        # print(train_month)\n",
    "        # print(train_day)\n",
    "        # print(train_hour)\n",
    "\n",
    "        # print(label_month)\n",
    "        # print(label_day)\n",
    "        # print(label_hour)\n",
    "        # raise ValueError\n",
    "        # print(raw_data_ts.shape)\n",
    "        # print(raw_data_weather.shape)\n",
    "        # print(label.shape)\n",
    "        return {'raw_data_ts':torch.from_numpy(raw_data_ts).float(),\n",
    "                'train_month':torch.from_numpy(train_month).long(),\n",
    "                'train_day':torch.from_numpy(train_day).long(),\n",
    "                'train_hour':torch.from_numpy(train_hour).long(),\n",
    "                'raw_data_weather':torch.from_numpy(raw_data_weather).float(),\n",
    "                'label':torch.from_numpy(label).float(),\n",
    "                'label_month':torch.from_numpy(label_month).long(),\n",
    "                'label_day':torch.from_numpy(label_day).long(),\n",
    "                'label_hour':torch.from_numpy(label_hour).long(),\n",
    "                }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = DataBase(start_train_date='20230201',\n",
    "                    end_train_date='20230328',\n",
    "                    start_test_date='20230301',\n",
    "                    end_test_date='20230331',\n",
    "                    data_dir='/Users/leroy/Documents/GitHub/Electricity_trading/DART/Data')\n",
    "\n",
    "trainning_dataloader, validation_dataloader = database.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) A small CNN to extract local features in (C, H, W)\n",
    "# -------------------------------------------------------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A small CNN block to process input weather data (B, 16, H, W) into (B, embed_dim, H, W).\n",
    "    You can expand with more layers, skip connections, etc. for better performance.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=16, out_channels=32):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, in_channels, H, W)\n",
    "        return self.conv_block(x)  # => (B, out_channels, H, W)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) DateTime Embedding\n",
    "# -------------------------------------------------------------------------\n",
    "class DateTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Embeds (month, day, hour) each of shape (batch_size, 3)\n",
    "    into a single vector of shape (batch_size, embed_dim).\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=16):\n",
    "        super().__init__()\n",
    "        self.month_embed = nn.Embedding(12, embed_dim)\n",
    "        self.day_embed   = nn.Embedding(31, embed_dim)\n",
    "        self.hour_embed  = nn.Embedding(24, embed_dim)\n",
    "        \n",
    "    def forward(self, month, day, hour):\n",
    "        month = month - 1\n",
    "        day = day - 1\n",
    "        hour = hour - 1\n",
    "        # Each is (batch_size, 3). We embed them individually:\n",
    "        # month_embed(month) => (batch_size, 3, embed_dim)\n",
    "        \n",
    "        month_emb = self.month_embed(month).mean(dim=1)  # => (batch_size, embed_dim)\n",
    "        day_emb   = self.day_embed(day).mean(dim=1)      # => (batch_size, embed_dim)\n",
    "        hour_emb  = self.hour_embed(hour).mean(dim=1)    # => (batch_size, embed_dim)\n",
    "        \n",
    "        # Combine them by summation (or you can concat and do a small MLP)\n",
    "        \n",
    "        combined = month_emb + day_emb + hour_emb\n",
    "        return combined  # => (batch_size, embed_dim)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) Spatial Positional Encoding in 2D form\n",
    "# -------------------------------------------------------------------------\n",
    "class SpatialPositionalEncoding2D(nn.Module):\n",
    "    \"\"\"\n",
    "    A 2D positional encoding for an 8x9 grid.\n",
    "    - row_embed has shape (8, embed_dim)\n",
    "    - col_embed has shape (9, embed_dim)\n",
    "    We sum row_embed[row] + col_embed[col] to get a unique embedding\n",
    "    for each (row, col).\n",
    "    \"\"\"\n",
    "    def __init__(self, grid_size=(8, 9), embed_dim=16):\n",
    "        super().__init__()\n",
    "        self.H, self.W = grid_size\n",
    "        self.row_embed = nn.Embedding(self.H, embed_dim)\n",
    "        self.col_embed = nn.Embedding(self.W, embed_dim)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Returns a 2D positional encoding of shape (embed_dim, H, W).\n",
    "        Typically you'd add this to your feature map of shape (B, embed_dim, H, W).\n",
    "        \"\"\"\n",
    "        device = self.row_embed.weight.device\n",
    "        \n",
    "        # row indices: 0..(H-1), col indices: 0..(W-1)\n",
    "        rows = torch.arange(self.H, device=device)  # shape (H,)\n",
    "        cols = torch.arange(self.W, device=device)  # shape (W,)\n",
    "        \n",
    "        # row_embed(rows) => (H, embed_dim)\n",
    "        # col_embed(cols) => (W, embed_dim)\n",
    "        row_emb = self.row_embed(rows)  # (H, embed_dim)\n",
    "        col_emb = self.col_embed(cols)  # (W, embed_dim)\n",
    "        \n",
    "        # Sum: broadcast to (H, W, embed_dim), then transpose to (embed_dim, H, W)\n",
    "        # row_emb => (H, 1, embed_dim)\n",
    "        # col_emb => (1, W, embed_dim)\n",
    "        # out => (H, W, embed_dim) => permute => (embed_dim, H, W)\n",
    "        pos_2d = row_emb.unsqueeze(1) + col_emb.unsqueeze(0)  # (H, W, embed_dim)\n",
    "        pos_2d = pos_2d.permute(2, 0, 1)  # => (embed_dim, H, W)\n",
    "        return pos_2d\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3) Attention-based Pooling over the flattened tokens\n",
    "# -------------------------------------------------------------------------\n",
    "class AttentionPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns a linear 'query' that produces a scalar attention score for each token.\n",
    "    Then uses softmax to get attention weights, and outputs a weighted sum.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=16):\n",
    "        super().__init__()\n",
    "        self.attn_query = nn.Linear(embed_dim, 1)  # (embed_dim) -> scalar\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, embed_dim)\n",
    "        returns (batch_size, embed_dim)\n",
    "        \"\"\"\n",
    "        # attn_logits => (batch_size, seq_len, 1)\n",
    "        attn_logits = self.attn_query(x)\n",
    "        attn_logits = attn_logits.squeeze(-1)  # => (batch_size, seq_len)\n",
    "        \n",
    "        attn_weights = F.softmax(attn_logits, dim=-1).unsqueeze(-1)  # => (batch_size, seq_len, 1)\n",
    "        pooled = (x * attn_weights).sum(dim=1)  # => (batch_size, embed_dim)\n",
    "        return pooled\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4) Transformer Model with \"Apply 2D Pos Encoding, then Flatten\"\n",
    "# -------------------------------------------------------------------------\n",
    "class TransformerModel2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Demonstrates how to:\n",
    "      - Keep the data in (B, C, H, W) shape initially.\n",
    "      - Apply a 1x1 conv (or linear) to project from 16 -> embed_dim in 2D form.\n",
    "      - Add the 2D positional embeddings (embed_dim, H, W).\n",
    "      - Flatten to (B, H*W, embed_dim).\n",
    "      - Add the temporal embedding (month/day/hour).\n",
    "      - Pass through Transformer.\n",
    "      - Use attention-based pooling for a final single embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dim=16,   # raw weather feature channels\n",
    "                 embed_dim=16, \n",
    "                 num_heads=4, \n",
    "                 num_layers=3, \n",
    "                 grid_size=(8,9)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.grid_size = grid_size  # (H=8, W=9)\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # 2D positional encoder (returns (embed_dim, H, W))\n",
    "        self.spatial_pe_2d = SpatialPositionalEncoding2D(grid_size, embed_dim)\n",
    "        \n",
    "        # 1x1 conv to project from input_dim -> embed_dim while preserving H,W\n",
    "        # If input_dim == embed_dim, you could skip this layer or make it an identity.\n",
    "        # self.feature_projection = nn.Conv2d(\n",
    "        #     in_channels=input_dim, \n",
    "        #     out_channels=embed_dim,\n",
    "        #     kernel_size=1, \n",
    "        #     bias=False\n",
    "        # )\n",
    "\n",
    "        self.feature_projection = SimpleCNN(in_channels=input_dim, out_channels=embed_dim)\n",
    "\n",
    "        # Embedding for (month, day, hour) => (batch_size, embed_dim)\n",
    "        # self.datetime_embed = DateTimeEmbedding(embed_dim)\n",
    "\n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Attention-based pooling\n",
    "        self.attn_pool = AttentionPool(embed_dim)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        \"\"\"\n",
    "        x: shape (batch_size, 16, 8, 9)\n",
    "        month/day/hour: (batch_size, 3)\n",
    "        \"\"\"\n",
    "        #minus 1 to make the month and day and hour start from 0\n",
    "        # month = month - 1\n",
    "        # day = day - 1\n",
    "        # hour = hour - 1\n",
    "        \n",
    "        B, C, H, W = x.shape\n",
    "        assert (H, W) == self.grid_size, \"Input grid size must match the set grid_size.\"\n",
    "\n",
    "        # 1) Project input features to embed_dim in 2D form:\n",
    "        #    (B, 16, 8, 9) -> (B, embed_dim, 8, 9)\n",
    "        x_proj = self.feature_projection(x)  # => (B, embed_dim, 8, 9)\n",
    "\n",
    "        # 2) Get 2D positional embedding => shape (embed_dim, 8, 9)\n",
    "        pos_2d = self.spatial_pe_2d()  # => (embed_dim, 8, 9)\n",
    "\n",
    "        # 3) Broadcast and add => (B, embed_dim, 8, 9)\n",
    "        #   pos_2d is (embed_dim, H, W). We add it to each batch example.\n",
    "        x_proj = x_proj + pos_2d.unsqueeze(0)  # broadcast over batch\n",
    "\n",
    "        # 4) Flatten spatial dimension => (B, embed_dim, 8*9) => (B, 72, embed_dim)\n",
    "        x_proj = x_proj.view(B, self.embed_dim, -1).permute(0, 2, 1)\n",
    "        # shape now: (batch_size, 72, embed_dim)\n",
    "\n",
    "        # 5) Embed the date/time => (B, embed_dim)\n",
    "        #directly use the time embedding\n",
    "        # time_emb = self.datetime_embed(month, day, hour)  # => (B, embed_dim)\n",
    "\n",
    "\n",
    "        # Expand to (B, 1, embed_dim) and broadcast to the 72 tokens\n",
    "        time_emb_2d = time_emb.unsqueeze(1).expand(-1, x_proj.size(1), -1)  # => (B, 72, embed_dim)\n",
    "\n",
    "        # 6) Combine the time embedding with the spatially encoded tokens\n",
    "        x_proj = x_proj + time_emb_2d  # add or could use another projection\n",
    "\n",
    "        # 7) Pass through Transformer\n",
    "        out = self.transformer_encoder(x_proj)  # => (B, 72, embed_dim)\n",
    "\n",
    "        # 8) Apply attention-based pooling => (B, embed_dim)\n",
    "        pooled = self.attn_pool(out)\n",
    "\n",
    "        return pooled\n",
    "\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class ProbMask():\n",
    "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
    "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
    "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
    "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    index, :].to(device)\n",
    "        self._mask = indicator.view(scores.shape).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "class DataEmbedding_inverted(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_inverted, self).__init__()\n",
    "        self.value_embedding = nn.Linear(c_in, d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x: [Batch Variate Time]\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x)\n",
    "        else:\n",
    "            # the potential to take covariates (e.g. timestamps) as tokens\n",
    "            x = self.value_embedding(torch.cat([x, x_mark.permute(0, 2, 1)], 1)) \n",
    "        # x: [Batch Variate d_model]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "class IT(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://arxiv.org/abs/2310.06625\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 seq_len,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 dropout=0.1,\n",
    "                 d_ff=2048,\n",
    "                 activation = 'gelu',\n",
    "                 e_layers = 2):\n",
    "        super(IT, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding_inverted(seq_len, d_model, embed_type='fixed', freq='h',\n",
    "                                                    dropout=dropout)\n",
    "        # Encoder-only architecture\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor=5, attention_dropout=dropout,\n",
    "                                      output_attention=False), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        # print(means.shape)\n",
    "        x_enc =  x_enc - means\n",
    "\n",
    "        stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc = x_enc / stdev\n",
    "\n",
    "        _, _, N = x_enc.shape # B L N\n",
    "        # B: batch_size;    E: d_model; \n",
    "        # L: seq_len;       S: pred_len;\n",
    "        # N: number of variate (tokens), can also includes covariates\n",
    "\n",
    "        # Embedding\n",
    "        # B L N -> B N E                (B L N -> B L E in the vanilla Transformer)\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc) # covariates (e.g timestamp) can be also embedded as tokens\n",
    "        # print(enc_out[0,:,:])\n",
    "        # B N E -> B N E                (B L E -> B L E in the vanilla Transformer)\n",
    "        # the dimensions of embedded time series has been inverted, and then processed by native attn, layernorm and ffn modules\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        \n",
    "        enc_out = enc_out.mean(1)\n",
    "        return enc_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "        return dec_out # [B, D]\n",
    "    \n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1):\n",
    "        super(CrossAttentionFusion, self).__init__()\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, query, key, value):\n",
    "        # query: (B*pred_hours, 1, embed_dim)\n",
    "        # key, value: (B*pred_hours, 2, embed_dim)\n",
    "        attn_output, _ = self.cross_attn(query, key, value)\n",
    "        query = self.norm1(query + attn_output)\n",
    "        ffn_output = self.ffn(query)\n",
    "        out = self.norm2(query + ffn_output)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5) Combined Predictor Model\n",
    "#    Uses cross-attention fusion (with residual connections) to fuse the weather\n",
    "#    and load latent representations based on target forecast time.\n",
    "# ============================================================================\n",
    "class CombinedGridLoadPredictor(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        weather_encoder: instance of TransformerModel2D (weather branch)\n",
    "        load_encoder: instance of ITEncoder (load branch)\n",
    "        latent_dim: shared embedding dimension (e.g., 32)\n",
    "        grid_size: (H, W) of the grid\n",
    "        pred_hours: number of forecast hours (e.g., 3)\n",
    "        datetime_embed: shared DateTimeEmbedding instance\n",
    "        \"\"\"\n",
    "        super(CombinedGridLoadPredictor, self).__init__()\n",
    "        self.weather_encoder = TransformerModel2D(\n",
    "                                                input_dim=config['input_dim'], \n",
    "                                                embed_dim=config['embed_dim'],  # let’s go bigger internally\n",
    "                                                num_heads=config['n_heads'], \n",
    "                                                num_layers=config['tf_num_layers'], \n",
    "                                                grid_size=config['grid_size']\n",
    "                                            )\n",
    "        self.load_encoder = IT(\n",
    "                                seq_len=config['seq_len'],\n",
    "                                d_model=config['embed_dim'],\n",
    "                                n_heads=config['n_heads'],\n",
    "                                dropout=config['dropout'],\n",
    "                                d_ff=int(config['embed_dim'] * 2),\n",
    "                            )\n",
    "        \n",
    "        self.datetime_embed = DateTimeEmbedding(embed_dim=config['embed_dim'])\n",
    "        \n",
    "        # Cross-attention fusion block.\n",
    "        # For each forecast hour, we form key/value from stacked weather and load latents.\n",
    "        self.cross_attn_fusion = CrossAttentionFusion(embed_dim=config['embed_dim'], n_heads=config['n_heads'])\n",
    "        \n",
    "        #output layer\n",
    "        self.out_layer = nn.Linear(config['embed_dim'], config['pred_hours'])\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        weather_data: (B, 16, 8, 9)\n",
    "        weather_time_info: (B, pred_hours, 3) for the weather forecast times\n",
    "        load_x_enc: (B, 168, 20)\n",
    "        load_x_mark_enc: (B, 168, 3)\n",
    "        target_time_info: (B, pred_hours, 3) for the downstream target times\n",
    "        \"\"\"\n",
    "        weather_data = batch['raw_data_weather']\n",
    "        pred_month = batch['label_month']\n",
    "        pred_day = batch['label_day']\n",
    "        pred_hour = batch['label_hour']\n",
    "\n",
    "        ts_data = batch['raw_data_ts']\n",
    "        ts_month = batch['train_month']\n",
    "        ts_day = batch['train_day']\n",
    "        ts_hour = batch['train_hour']\n",
    "\n",
    "        B = weather_data.size(0)\n",
    "        # External embeddings using the shared DateTimeEmbedding\n",
    "        target_time_emb = self.datetime_embed(pred_month, pred_day, pred_hour) # (B, latent_dim)\n",
    "        \n",
    "        # Weather branch: produce weather latent per forecast hour → (B, latent_dim)\n",
    "        weather_latent = self.weather_encoder(weather_data, target_time_emb)\n",
    "\n",
    "        #create x_mark for the load encoder\n",
    "        load_x_mark_enc = torch.cat([ts_month.unsqueeze(-1), ts_day.unsqueeze(-1), ts_hour.unsqueeze(-1)], dim=-1) # (B, T, 3)\n",
    "        \n",
    "        # Load branch: produce a single latent → (B, latent_dim); replicate for forecast hours.\n",
    "        load_latent = self.load_encoder(ts_data, load_x_mark_enc, None, None)  # (B, latent_dim)\n",
    "        \n",
    "\n",
    "        \n",
    "        # For each forecast hour, form a key-value pair by stacking the two latents.\n",
    "        # keys: (B, 2, latent_dim)\n",
    "        keys = torch.stack([weather_latent, load_latent], dim=1)\n",
    "\n",
    "        # Query: use target time embedding for each forecast hour → (B, 1, latent_dim)\n",
    "        query = target_time_emb.unsqueeze(1)\n",
    "        \n",
    "        # Apply cross-attention fusion\n",
    "        fused = self.cross_attn_fusion(query, keys, keys)  # (B*pred_hours, 1, latent_dim)\n",
    "        \n",
    "        #get prediction\n",
    "        pred = self.out_layer(fused.squeeze(1))\n",
    "        \n",
    "        return {'pred':pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainner:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 optim,\n",
    "                 scaler,\n",
    "                 device,\n",
    "                 lr,\n",
    "                 loss_fn,\n",
    "                 trainning_dataloader,\n",
    "                 validation_dataloader,\n",
    "                 testing_dataloader,\n",
    "                 scheduler_name = None,\n",
    "                 scheduler_max_step = 20,\n",
    "                 scheduler_min_lr = 1e-9,\n",
    "                 max_epoch = 50,\n",
    "                 exit_count = 15,\n",
    "                 model_name = 'best_model_weights.pt',\n",
    "                 output_filaname = 'output.txt',\n",
    "                 loss_plot = 'loss.png',\n",
    "                 show = True,\n",
    "                 gradient_clip = True,\n",
    "                 max_gradient_norm = 1,\n",
    "                 gamma = 2,\n",
    "                 poly_power = 2,\n",
    "                 mixed_percision_type = torch.bfloat16\n",
    "                 ):\n",
    "        '''\n",
    "        This Trainer class handles the model training, validation, and testing process. \n",
    "        It supports various learning rate schedules, gradient clipping, mixed precision training, \n",
    "        and backtesting of the model performance.\n",
    "        '''\n",
    "        \n",
    "        # Initialize model, optimizers, dataloaders, and training settings\n",
    "        self.model = model.to(device)\n",
    "        self.trainning_dataloader = trainning_dataloader\n",
    "        self.validation_dataloader = validation_dataloader\n",
    "        self.testing_dataloader = testing_dataloader\n",
    "        self.device = device\n",
    "        self.optim = optim\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.max_epcoh = max_epoch\n",
    "        self.exit_count = exit_count\n",
    "        self.validation_loss_list = []\n",
    "        self.trainning_loss_list = []\n",
    "        self.model_name = model_name\n",
    "        self.output_filaname = output_filaname\n",
    "        self.show = show\n",
    "        self.gradient_clip = gradient_clip\n",
    "        self.max_gradient_norm = max_gradient_norm\n",
    "        self.scaler = scaler\n",
    "        self.mixed_percision_type = mixed_percision_type\n",
    "        self.loss_plot = loss_plot\n",
    "    \n",
    "        # Learning rate scheduler\n",
    "        if self.scheduler_name == 'cos':\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optim, T_max=scheduler_max_step, eta_min=scheduler_min_lr)\n",
    "\n",
    "        elif self.scheduler_name == 'expo':\n",
    "            self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optim, gamma=gamma)\n",
    "\n",
    "        elif self.scheduler_name == 'poly':\n",
    "            self.scheduler = torch.optim.lr_scheduler.PolynomialLR(self.optim, power=poly_power,total_iters=max_epoch)\n",
    "\n",
    "\n",
    "    def log_print(self,out):\n",
    "        '''\n",
    "        Print logs to both console and output file (if `self.show` is True).\n",
    "        '''\n",
    "        if self.show:\n",
    "            with open(self.output_filaname, \"a\") as f:\n",
    "                print(out, file=f)\n",
    "                print(out)\n",
    "\n",
    "    def validation(self):\n",
    "        '''\n",
    "        Run validation on the validation dataset and return the average loss.\n",
    "        This function also computes the Sharpe ratio and PnL per trade for validation.\n",
    "        '''\n",
    "\n",
    "        loss_list = []\n",
    "        element_loss = []\n",
    "\n",
    "        # Disable gradient calculation for validation\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            if self.show:\n",
    "                pbar = tqdm(self.validation_dataloader, desc='Validation',unit='batch')\n",
    "            else:\n",
    "                pbar = self.validation_dataloader\n",
    "\n",
    "            for batch in pbar:\n",
    "                # Move batch data to the correct device (GPU or CPU)\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                label = batch['label']\n",
    "\n",
    "                output_dict = self.model(batch)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss_dict = self.loss_fn(output_dict,label)\n",
    "\n",
    "                loss = loss_dict['loss']\n",
    "                loss_list.append(loss.cpu().numpy())\n",
    "                element_loss.append([i.item() for i in loss_dict.values()])\n",
    "\n",
    "        element_loss_df = pd.DataFrame(element_loss,columns=list(loss_dict.keys())).mean()\n",
    "        self.log_print(f'validation element wise loss: {element_loss_df}')\n",
    "        \n",
    "        return np.mean(loss_list)\n",
    "\n",
    "    def trainning_epoch(self):\n",
    "        '''\n",
    "        Run one epoch of training and return the average training loss and validation loss.\n",
    "        This function also computes the Sharpe ratio for the training data.\n",
    "        '''\n",
    "        epoch_loss = []\n",
    "        element_loss = []\n",
    "\n",
    "        self.model.train()\n",
    "        if self.show:\n",
    "            pbar = tqdm(self.trainning_dataloader, desc='Trainning',unit='batch')\n",
    "        else:\n",
    "            pbar = self.trainning_dataloader\n",
    "\n",
    "\n",
    "        for batch in pbar:\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            label = batch['label']\n",
    "\n",
    "            # Mixed precision training (if using GPU)\n",
    "            if self.device == 'cuda':\n",
    "                with torch.cuda.amp.autocast(dtype=self.mixed_percision_type):\n",
    "                    output_dict = self.model(batch)\n",
    "                    loss_dict = self.loss_fn(output_dict,label)\n",
    "                    loss = loss_dict['loss']\n",
    "                # Backpropagation\n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                output_dict = self.model(batch)\n",
    "                loss_dict = self.loss_fn(output_dict,label)\n",
    "                loss = loss_dict['loss']\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "            \n",
    "\n",
    "            # Gradient clipping to avoid exploding gradients\n",
    "            if self.gradient_clip:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_gradient_norm)\n",
    "\n",
    "            # Optimizer step and scaler update (for mixed precision)\n",
    "            if self.device == 'cuda':\n",
    "                self.scaler.step(self.optim)\n",
    "                self.scaler.update()\n",
    "                self.optim.zero_grad()\n",
    "            else:\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "\n",
    "            if self.show:\n",
    "                show_dict = {}\n",
    "\n",
    "                for name,value in loss_dict.items():\n",
    "                    show_dict[name] = value.item()\n",
    "\n",
    "                pbar.set_postfix(show_dict)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            element_loss.append([i.item() for i in loss_dict.values()])\n",
    "\n",
    "        # Run validation and calculate Sharpe ratio for training\n",
    "        loss_valid = self.validation()\n",
    "\n",
    "        #get element wise loss\n",
    "        element_loss_df = pd.DataFrame(element_loss,columns=list(loss_dict.keys())).mean()\n",
    "        self.log_print(f'training element wise loss: {element_loss_df}')\n",
    "\n",
    "        return np.mean(epoch_loss), loss_valid\n",
    "\n",
    "    def train_main(self):\n",
    "        '''\n",
    "        Main training loop. It performs training and validation, saves the best model,\n",
    "        and implements early stopping if validation loss does not improve.\n",
    "        '''\n",
    "\n",
    "        best_loss = 1e7\n",
    "\n",
    "        flat_count = 0\n",
    "        for i in range(self.max_epcoh):\n",
    "\n",
    "            train_loss, val_loss = self.trainning_epoch()\n",
    "            self.trainning_loss_list.append(train_loss)\n",
    "\n",
    "\n",
    "            self.log_print(f'epoch {i} loss {train_loss}; validation {i} loss {val_loss}')\n",
    "\n",
    "            # Adjust learning rate with scheduler if enabled\n",
    "            if self.scheduler_name is not None:\n",
    "                self.scheduler.step()\n",
    "                self.lr = self.scheduler.get_last_lr()\n",
    "            self.log_print(f'current lr is :{self.lr}')\n",
    "\n",
    "            #Free up memory for GPU\n",
    "            if self.device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Save model if validation loss improves\n",
    "            if val_loss < best_loss:\n",
    "                torch.save(self.model.state_dict(), self.model_name)\n",
    "                best_loss = val_loss\n",
    "                flat_count = 0\n",
    "            else:\n",
    "                flat_count += 1\n",
    "\n",
    "            if flat_count > self.exit_count:\n",
    "                self.log_print('validation loss is not improving, stop')\n",
    "                break\n",
    "\n",
    "            gc.collect()\n",
    "            self.validation_loss_list.append(val_loss)\n",
    "\n",
    "        # Load the best model for final testing\n",
    "        self.log_print('load model with best validation score')\n",
    "        checkpoint = torch.load(self.model_name)\n",
    "        self.model.load_state_dict(checkpoint)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(self.trainning_loss_list, label=\"Training Loss\", marker=\"o\")\n",
    "        plt.plot(self.validation_loss_list, label=\"Validation Loss\", marker=\"s\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Loss Curve\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(\"loss_curve.png\")  # Save the figure\n",
    "        # plt.show()\n",
    "\n",
    "        if not self.show:\n",
    "            self.log_print(f'finish trainning, best valid score: {best_loss}')\n",
    "        return best_loss\n",
    "\n",
    "class Customized_MAE(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.mae = nn.L1Loss()\n",
    "\n",
    "    def __call__(self, output_dict,label):\n",
    "        pred = output_dict['pred']\n",
    "        # print(pred.shape)\n",
    "        # print(label.shape)\n",
    "        # raise ValueError\n",
    "        loss = self.mae(pred,label)\n",
    "\n",
    "        return {'loss':loss, \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leroy/Documents/GitHub/Electricity_trading/venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Trainning:   0%|          | 0/8 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainning: 100%|██████████| 8/8 [00:01<00:00,  5.05batch/s, loss=0.928]\n",
      "Validation: 100%|██████████| 4/4 [00:00<00:00, 20.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation element wise loss: loss    0.777909\n",
      "dtype: float64\n",
      "training element wise loss: loss    0.936737\n",
      "dtype: float64\n",
      "epoch 0 loss 0.9367367327213287; validation 0 loss 0.7779088020324707\n",
      "current lr is :[0.0009938441764533986]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainning: 100%|██████████| 8/8 [00:01<00:00,  5.20batch/s, loss=0.302]\n",
      "Validation: 100%|██████████| 4/4 [00:00<00:00, 21.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation element wise loss: loss    0.777909\n",
      "dtype: float64\n",
      "training element wise loss: loss    0.861717\n",
      "dtype: float64\n",
      "epoch 1 loss 0.8617171086370945; validation 1 loss 0.7779088020324707\n",
      "current lr is :[0.0009755282826193188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainning: 100%|██████████| 8/8 [00:01<00:00,  5.76batch/s, loss=1]    \n",
      "Validation: 100%|██████████| 4/4 [00:00<00:00, 22.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation element wise loss: loss    0.777909\n",
      "dtype: float64\n",
      "training element wise loss: loss    0.945774\n",
      "dtype: float64\n",
      "epoch 2 loss 0.9457735121250153; validation 2 loss 0.7779088020324707\n",
      "current lr is :[0.000945503316590922]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainning: 100%|██████████| 8/8 [00:01<00:00,  5.46batch/s, loss=1.36] \n",
      "Validation: 100%|██████████| 4/4 [00:00<00:00, 22.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation element wise loss: loss    0.777909\n",
      "dtype: float64\n",
      "training element wise loss: loss    0.990655\n",
      "dtype: float64\n",
      "epoch 3 loss 0.9906546622514725; validation 3 loss 0.7779088020324707\n",
      "current lr is :[0.0009045085926789767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainning: 100%|██████████| 8/8 [00:01<00:00,  5.52batch/s, loss=0.599]\n",
      "Validation: 100%|██████████| 4/4 [00:00<00:00, 22.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation element wise loss: loss    0.777909\n",
      "dtype: float64\n",
      "training element wise loss: loss    0.898662\n",
      "dtype: float64\n",
      "epoch 4 loss 0.898661807179451; validation 4 loss 0.7779088020324707\n",
      "current lr is :[0.0008535535370398833]\n",
      "validation loss is not improving, stop\n",
      "load model with best validation score\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7779088"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = {'input_dim':16,\n",
    "                'embed_dim':64,\n",
    "                'n_heads':4,\n",
    "                'tf_num_layers':3,\n",
    "                'grid_size':(8,9),\n",
    "                'seq_len':168,\n",
    "                'dropout':0.1,\n",
    "                'pred_hours':3,\n",
    "                }\n",
    "\n",
    "trainner_config = {'lr':1e-3,\n",
    "                    'scheduler_name':'cos',\n",
    "                    'scheduler_max_step':20,\n",
    "                    'scheduler_min_lr':1e-9,\n",
    "                    'max_epoch':5,\n",
    "                    'exit_count':3,\n",
    "                    'model_name':'best_model_weights.pt',\n",
    "                    'output_filaname':'output.txt',\n",
    "                    'loss_plot':'loss.png',\n",
    "                    'show':True,\n",
    "                    'gradient_clip':True,\n",
    "                    'max_gradient_norm':1,\n",
    "                    'gamma':2,\n",
    "                    'poly_power':2,\n",
    "                    'mixed_percision_type':torch.bfloat16\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "model = CombinedGridLoadPredictor(model_config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = trainner_config['lr'])\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "trainner = Trainner(model = CombinedGridLoadPredictor(model_config),\n",
    "                    optim = optimizer,\n",
    "                    scaler = scaler,\n",
    "                    device = 'cpu',\n",
    "                    loss_fn = Customized_MAE(),\n",
    "                    trainning_dataloader = trainning_dataloader,\n",
    "                    validation_dataloader = validation_dataloader,\n",
    "                    testing_dataloader = None,\n",
    "                    **trainner_config)\n",
    "\n",
    "trainner.train_main()\n",
    "\n",
    "# for batch in trainning_dataloader:\n",
    "#     # print(batch['raw_data_weather'].shape)\n",
    "\n",
    "#     input_data = batch['raw_data_weather']\n",
    "#     month = batch['label_month']\n",
    "#     day = batch['label_day']\n",
    "#     hour = batch['label_hour']\n",
    "\n",
    "#     # print(batch['train_month'].shape)\n",
    "#     # print(hour)\n",
    "\n",
    "#     pred = model(batch)\n",
    "#     print(pred.shape)\n",
    "\n",
    "#     # print(latent_output.shape)  # (batch_size, embed_dim)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
